{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titile: DNA Distance Analysis\n",
    "- Research from Fu-Chi Yang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import random\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import utils_final\n",
    "# sys.path.append('/home/cptsai/catkin_ws/src/fuchi_research_1019/ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch0: Term Definition\n",
    "\n",
    "- *fullName*: \n",
    "    - The name of each individual, ex: **EUL203**\n",
    "- *race*\n",
    "    - 3 different races, which is: **[black/white/yellow]**\n",
    "- *class*\n",
    "    - 35 different classes, which is **[EU, KC, TSO, P, RUK, ...]**\n",
    "- *subpop*\n",
    "    - 15 different subpop, which is:\n",
    "        - **black**\n",
    "        - **white**\n",
    "        - yellow: **TSO, HAN, AMI, ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch1: Data-Preprocessing\n",
    "- initially, we need to read the raw data into the program\n",
    "- then we can sort the neighbors of each individual by the distance value\n",
    "- then we can use Pandas to handle the data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> read data by pandas\n",
    "df_all = pd.read_csv('data_list_nxn_table.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> choose a sub-section for your whole data-set\n",
    "df = df_all\n",
    "# df = df_all.iloc[0:1600,0:200]\n",
    "# df = df_all.iloc[:,:]\n",
    "# df.head()\n",
    "# df = df_all.iloc[:,0:6]\n",
    "# access the element by iloc\n",
    "# df.iloc[0:5,:]\n",
    "# df\n",
    "# df.shape[1]\n",
    "# df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch2 KNN (K-Nearest-Neighbor) \n",
    "- after the initial data pre-processing, we can start **KNN** to see the relation between distance and DNA class\n",
    "- pick a K value, and assign the prediction of the individual as the most common class among the neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Progress:  99.97 %\n"
     ]
    }
   ],
   "source": [
    "# ---- start KNN -----\n",
    "K = 1\n",
    "[original_race_array_KNN, predicted_race_array_KNN] = utils_final.k_nearest_neighbor(df, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_race_array_KNN[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_race_array_KNN[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Correct] Y2Y_accuracy:  0.9874371859296482\n",
      "\n",
      " [Wrong  ] Y2W_accuracy:  0.011306532663316583\n",
      "\n",
      " [Wrong  ] Y2B_accuracy:  0.001256281407035176\n",
      "\n",
      " [Wrong  ] W2Y_accuracy:  0.020795660036166366\n",
      "\n",
      " [Correct] W2W_accuracy:  0.9755877034358047\n",
      "\n",
      " [Wrong  ] W2B_accuracy:  0.003616636528028933\n",
      "\n",
      " [Wrong  ] B2Y_accuracy:  0.03208556149732621\n",
      "\n",
      " [Wrong  ] B2W_accuracy:  0.0106951871657754\n",
      "\n",
      " [Correct] B2B_accuracy:  0.9572192513368984\n"
     ]
    }
   ],
   "source": [
    "# >>> 個別種族的正確率EX.[han, thana, han_ko ...]\n",
    "\n",
    "# >>> old code\n",
    "# [lst_correct_percent, lst_correct, lst_total] = utils_final.analyze_individual_race_accuracy(original_race_array_KNN, predicted_race_array_KNN)\n",
    "\n",
    "# >>> new code\n",
    "[Y2Y_accuracy, Y2W_accuracy, Y2B_accuracy, W2Y_accuracy, W2W_accuracy, W2B_accuracy, B2Y_accuracy, B2W_accuracy, B2B_accuracy] = utils_final.analyze_individual_race_accuracy(original_race_array_KNN, predicted_race_array_KNN)\n",
    "\n",
    "print(\"\\n [Correct] Y2Y_accuracy: \", Y2Y_accuracy)\n",
    "print(\"\\n [Wrong  ] Y2W_accuracy: \", Y2W_accuracy)\n",
    "print(\"\\n [Wrong  ] Y2B_accuracy: \", Y2B_accuracy)\n",
    "print(\"\\n [Wrong  ] W2Y_accuracy: \", W2Y_accuracy)\n",
    "print(\"\\n [Correct] W2W_accuracy: \", W2W_accuracy)\n",
    "print(\"\\n [Wrong  ] W2B_accuracy: \", W2B_accuracy)\n",
    "print(\"\\n [Wrong  ] B2Y_accuracy: \", B2Y_accuracy)\n",
    "print(\"\\n [Wrong  ] B2W_accuracy: \", B2W_accuracy)\n",
    "print(\"\\n [Correct] B2B_accuracy: \", B2B_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Note]**: From above, we can know that when K=1, the race accuracy is higher than 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9794921875\n"
     ]
    }
   ],
   "source": [
    "# letʼs check the similarity of the two lists (Ex. han=thana=han_ko)\n",
    "accuracy = utils_final.getAccuracyOfTwoLists(original_race_array_KNN, predicted_race_array_KNN)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Note]**: From above, we know that we can get pretty good prediction simply by KNN (when K = 1), let's change the K-value and see the results.  \n",
    "In short, \n",
    "- In the above, we set K as a constant.\n",
    "- In the KNN problem, the value of K is important, since different dataset needs an optimal K.\n",
    "- So, letʼs set K as a variable, and execute KNN again, and find out what is the besk K value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file \n",
    "# file = open(\"knn_result.csv\", \"w\") # open file\n",
    "# file.write(\"Index,Population,Correct,Total,Accuracy\\n\") # print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- start KNN with variable K -----\n",
    "k_range = 4\n",
    "k_array = []\n",
    "accuracy_array = []\n",
    "for k in range(1, k_range):\n",
    "    k_array.append(k)\n",
    "    \n",
    "    [original_race_array, predicted_race_array] = utils.k_nearest_neighbor(df, k)\n",
    "    accuracy = utils.getAccuracyOfTwoLists(original_race_array, predicted_race_array)\n",
    "    accuracy_array.append(accuracy)\n",
    "    print(\"k: \", k, \", accuracy: \", accuracy)\n",
    "    \n",
    "    # write to file ...\n",
    "    # file.write(\"----k = \")\n",
    "    # file.write(str(k))\n",
    "    # file.write(\"----\\n\")\n",
    "    # [lst_correct_percent, lst_correct, lst_total] = utils.analyze_individual_class_accuracy(original_class_array, predicted_class_array)\n",
    "    # print the content ...\n",
    "    # utils.write2file(file, lst_correct_percent, lst_correct, lst_total)\n",
    "\n",
    "# file.close() # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letʼs show the result with a plot\n",
    "utils.plot_k_vs_accuracy(k_array, accuracy_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(neighborClassType)\n",
    "print(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "# print(df.loc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Weighted Clustering\n",
    "In this section, we try to cluster the race (YWB) and subpopulation by Distance Weighted Clustering. \n",
    "\n",
    "\n",
    "We train for an optimal distance (d*) based on our algorithm, then get the weighted prediction\n",
    "\n",
    "## Distance Training\n",
    "In this section, we have to train for our d*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_star_array = []\n",
    "d_star = 0\n",
    "d_star_init = 0.001;\n",
    "d_star_gap  = 0.0003;\n",
    "min_d_to_perfect = 1000000;\n",
    "for j in range(5): \n",
    "    print(\"d_star_init:\", d_star_init)\n",
    "    d_to_perfect = utils3.distance_threshold_clustering(df, d_star_init);\n",
    "    print(\"d_to_perfect:\", d_to_perfect)\n",
    "    \n",
    "    # update your d*\n",
    "    if (d_to_perfect < min_d_to_perfect):\n",
    "        print(\"d* has been updated ...\")\n",
    "        min_d_to_perfect = d_to_perfect\n",
    "        d_star = d_star_init\n",
    "    d_star_init = d_star_init + d_star_gap\n",
    "d_star_array.append(d_star)\n",
    "d_star = mean(d_star_array)\n",
    "print(\"d* is\", d_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Distance Weighted Clustering\n",
    "From above, we get the optimal distance (d*). \n",
    "We can then run the algorithm for the unknown input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random row as the unknown input\n",
    "# (should read from file in the future)\n",
    "random_num = random.randrange(0, df.shape[0])\n",
    "unknown = df.iloc[random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_race_list = utils3.predict_race(unknown, d_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_race_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_list = utils3.predict_subpop(unknown, d_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KND (K-Nearest-Distance)\n",
    "- Take a closer look to the raw data, we can observe that some of the distances are the same. \n",
    "- So instead of KNN, we can see what happens to KND (K-nearest-distance)\n",
    "- In other words, pick \"K\" nearest distance, which includes more than (or equal to) K neighbors.\n",
    "- Letʼs see what the result looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "[original_class_array_KND, predicted_class_array_KND] = utils.k_nearest_distance(df, K)\n",
    "accuracy = utils.getAccuracyOfTwoLists(original_class_array_KND, predicted_class_array_KND)\n",
    "print(\"K: \", K, \", accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lst_correct_percent, lst_correct, lst_total] = utils.analyze_individual_class_accuracy(original_class_array_KND, predicted_class_array_KND)\n",
    "print(\"\\n lst_correct_percent:\\n\", lst_correct_percent)\n",
    "print(\"\\n lst_correct:\\n\", lst_correct)\n",
    "print(\"\\n lst_total:\\n\", lst_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letʼs see what the result looks like\n",
    "print(\"original_class_array_KND: \", original_class_array_KND)\n",
    "print(\"\\n\\n\")\n",
    "print(\"predicted_class_array_KND: \", predicted_class_array_KND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letʼs check the similarity of the two lists\n",
    "accuracy = utils.getAccuracyOfTwoLists(original_class_array_KND, predicted_class_array_KND)\n",
    "print(\"accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Letʼs check K value\n",
    "- Again, just like what weʼve discussed above, we need to tune k value for this dataset.\n",
    "- So letʼs use for-loop to automize the process and check the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file \n",
    "file = open(\"knd_result.csv\", \"w\") # open file\n",
    "file.write(\"Index,Population,Correct,Total,Accuracy\\n\") # print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- start KND with variable K -----\n",
    "k_range = 10\n",
    "k_array = []\n",
    "accuracy_array = []\n",
    "for k in range(1, k_range):\n",
    "    k_array.append(k)\n",
    "    \n",
    "    [original_class_array, predicted_class_array] = utils.k_nearest_distance(df, k)\n",
    "    \n",
    "    accuracy = utils.getAccuracyOfTwoLists(original_class_array, predicted_class_array)\n",
    "    accuracy_array.append(accuracy)\n",
    "    print(\"k: \", k, \", accuracy: \", accuracy)\n",
    "      \n",
    "    # write to file ...\n",
    "    file.write(\"----k = \")\n",
    "    file.write(str(k))\n",
    "    file.write(\"----\\n\")\n",
    "    [lst_correct_percent, lst_correct, lst_total] = utils.analyze_individual_class_accuracy(original_class_array, predicted_class_array)\n",
    "    # print the content ...\n",
    "    utils.write2file(file, lst_correct_percent, lst_correct, lst_total)\n",
    "    \n",
    "\n",
    "\n",
    "file.close() # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letʼs show the result with a plot\n",
    "utils.plot_k_vs_accuracy(k_array, accuracy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the distance information\n",
    "- We havenʼt use any distance value information above.\n",
    "- In this section, we can include this information in our prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KWNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1\n",
    "[original_class_array_KWNN, predicted_class_array_KWNN] = utils.k_weighted_nearest_neighbor(df, K)\n",
    "#accuracy = utils.getAccuracyOfTwoLists(original_class_array, predicted_class_array)\n",
    "#print(\"K: \", K, \", accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(original_class_array_KWNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_class_array_KWNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lst_correct_percent, lst_correct, lst_total] = utils.analyze_individual_class_accuracy(original_class_array_KWNN, predicted_class_array_KWNN)\n",
    "print(\"\\n lst_correct_percent:\\n\", lst_correct_percent)\n",
    "print(\"\\n lst_correct:\\n\", lst_correct)\n",
    "print(\"\\n lst_total:\\n\", lst_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the K value\n",
    "- Still, we need a for-loop to get the best K in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file \n",
    "file = open(\"kwnn_result.csv\", \"w\") # open file\n",
    "file.write(\"Index,Population,Correct,Total,Accuracy\\n\") # print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- start KWNN with variable K -----\n",
    "k_range = 15\n",
    "k_array = []\n",
    "accuracy_array = []\n",
    "for k in range(1, k_range):\n",
    "    k_array.append(k)\n",
    "    \n",
    "    [original_class_array, predicted_class_array] = utils.k_weighted_nearest_neighbor(df, k)\n",
    "    \n",
    "    # accuracy = utils.getAccuracyOfTwoLists(original_class_array, predicted_class_array)\n",
    "    accuracy = utils.getGeneralAccuracyOfTwoLists(original_class_array, predicted_class_array)\n",
    "    \n",
    "    accuracy_array.append(accuracy)\n",
    "    print(\"k: \", k, \", accuracy: \", accuracy)\n",
    "    \n",
    "    # write to file ...\n",
    "    file.write(\"----k = \")\n",
    "    file.write(str(k))\n",
    "    file.write(\"----\\n\")\n",
    "    [lst_correct_percent, lst_correct, lst_total] = utils.analyze_individual_class_accuracy(original_class_array, predicted_class_array)\n",
    "    # print the content ...\n",
    "    utils.write2file(file, lst_correct_percent, lst_correct, lst_total)\n",
    "    \n",
    "\n",
    "\n",
    "file.close() # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letʼs check the result\n",
    "utils.plot_k_vs_accuracy(k_array, accuracy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KWND\n",
    "Well, the (weighted+KNN) seems reasonable, letʼs try (weighted+KND) then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "[original_class_array, predicted_class_array] = utils.k_weighted_nearest_distance(df, K)\n",
    "accuracy = utils.getAccuracyOfTwoLists(original_class_array, predicted_class_array)\n",
    "print(\"K: \", K, \", accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, tune the best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file \n",
    "file = open(\"kwnd_result.csv\", \"w\") # open file\n",
    "file.write(\"Index,Population,Correct,Total,Accuracy\\n\") # print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- start KWND with variable K -----\n",
    "k_range = 15\n",
    "k_array = []\n",
    "accuracy_array = []\n",
    "for k in range(1, k_range):\n",
    "    k_array.append(k)\n",
    "    \n",
    "    [original_class_array, predicted_class_array] = utils.k_weighted_nearest_distance(df, k)\n",
    "    \n",
    "    # accuracy = utils.getAccuracyOfTwoLists(original_class_array, predicted_class_array)\n",
    "    accuracy = utils.getGeneralAccuracyOfTwoLists(original_class_array, predicted_class_array)\n",
    "    \n",
    "    accuracy_array.append(accuracy)\n",
    "    print(\"k: \", k, \", accuracy: \", accuracy)\n",
    "    \n",
    "    # write to file ...\n",
    "    file.write(\"----k = \")\n",
    "    file.write(str(k))\n",
    "    file.write(\"----\\n\")\n",
    "    [lst_correct_percent, lst_correct, lst_total] = utils.analyze_individual_class_accuracy(original_class_array, predicted_class_array)\n",
    "    # print the content ...\n",
    "    utils.write2file(file, lst_correct_percent, lst_correct, lst_total)\n",
    "    \n",
    "\n",
    "\n",
    "file.close() # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letʼs check the result\n",
    "utils.plot_k_vs_accuracy(k_array, accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the distance threshold\n",
    "From above, we know that weighted distance seems reasonable, now instead of using k (since there is no way to optimize it), let's use distance as a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide distance_threshold value (can use ML skill in the future, for now just tuning)\n",
    "# we can use the \"diagonal distance\" as the standard \n",
    "distance_threshold = 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the distance_threshold to the clustering algorithm\n",
    "[original_class_array, predicted_class_array] = utils2.distance_threshold_clustering(df, distance_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = utils.getAccuracyOfTwoLists(original_class_array, predicted_class_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
